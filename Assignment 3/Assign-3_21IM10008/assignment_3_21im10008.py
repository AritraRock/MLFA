# -*- coding: utf-8 -*-
"""assignment_3_21IM10008.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XhHSh96VwJaMeMjHbrJIPsPl7ax2QYmE

***Aritra Ray***

***21IM10008***
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tabulate import tabulate

"""# Experiment 1"""

df=pd.read_csv('BostonHousingDataset.csv')
# Dropped columns 'B' and 'LSTAT'
dataset_altered = df.drop(columns=['B', 'LSTAT'])

# Dropped rows with NaN values
dataset_altered = dataset_altered.dropna()

# Converted integer values to floating point
dataset_altered = dataset_altered.astype(float)

# Displayed the first 10 rows
print("First 10 rows of dataset_altered:")
print(dataset_altered.head(10))
# Export the DataFrame to Excel
dataset_altered_head=dataset_altered.head(10)
excel_filename = "dataset_altered_head.xlsx"
dataset_altered_head.to_excel(excel_filename, index=False)
print(f"DataFrame exported to '{excel_filename}'")

"""# Experiment 2"""

plt.figure(figsize=(15,5))
plt.subplot(1, 3, 1)
sns.histplot(dataset_altered['NOX'], bins=20, kde=True)
plt.title('NOX Histogram')
plt.subplot(1, 3, 2)
sns.histplot(dataset_altered['RM'], bins=20, kde=True)
plt.title('RM Histogram')
plt.subplot(1, 3, 3)
sns.histplot(dataset_altered['AGE'], bins=20, kde=True)
plt.title('AGE Histogram')

# Plotting correlation matrix heatmap
plt.figure(figsize=(8, 5))
correlation_matrix = dataset_altered.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix Heatmap')
plt.show()

"""# Experiment 3"""

dataset_altered.reset_index(inplace=True,drop=True)
dataset_altered_features = dataset_altered.drop(columns=['MEDV'])
dataset_altered_target = dataset_altered['MEDV']
dataset_altered_features_train, dataset_altered_features_test, dataset_altered_target_train, dataset_altered_target_test = train_test_split(dataset_altered_features, dataset_altered_target, test_size=0.1, shuffle=False, random_state=100)
y_train=dataset_altered_target_train
print("Shapes of training and testing subsets:")
print("dataset_altered_features_train:", dataset_altered_features_train.shape)
print("dataset_altered_features_test:", dataset_altered_features_test.shape)
print("dataset_altered_target_train:", dataset_altered_target_train.shape)
print("dataset_altered_target_test:", dataset_altered_target_test.shape)

"""# Experiment 4"""

class LR_ClosedForm:
    def __init__(self):
        self.coefficients = None
        self.intercept = None

    def fit(self, X, y):
        X_b = np.c_[np.ones((X.shape[0], 1)), X]  # Added bias term
        theta = np.linalg.inv((X_b.T).dot(X_b)).dot(X_b.T).dot(y)
        self.intercept = theta[0]
        self.coefficients = theta[1:]

    def predict(self, X):
        X_b = np.c_[np.ones((X.shape[0], 1)), X]  # Added bias term
        return X_b.dot(np.hstack((self.intercept, self.coefficients)))

# Training the model
closed_form_lr = LR_ClosedForm()
closed_form_lr.fit(dataset_altered_features_train, dataset_altered_target_train)
# Printing intercept and coefficients
print("Intercept:", closed_form_lr.intercept)
print("Coefficients:", closed_form_lr.coefficients)

# Prediction on testing data
dataset_altered_target_pred_closed_form = closed_form_lr.predict(dataset_altered_features_test)

# Calculated RMSE
def rmse(y_true, y_pred):
    return np.sqrt(np.mean((y_true - y_pred) ** 2))

rmse_closed_form = rmse(dataset_altered_target_test, dataset_altered_target_pred_closed_form)
print("RMSE for Closed Form Linear Regression:", rmse_closed_form)

"""#Experiment 5

"""

from sklearn.preprocessing import StandardScaler
class LR_Gradient:
    def __init__(self, learning_rate=0.01):
        self.learning_rate = learning_rate
        self.n_iterations = 30
        self.coefficients = 0
        self.intercept = 0

    def fit(self, X, y):
        X_b = np.c_[np.ones((X.shape[0], 1)), X]# Added bias term
        n_samples, n_features = X_b.shape
        scaler = StandardScaler()
        # Fit scaler to training data and transform it
        X_b = scaler.fit_transform(X_b)
        theta = np.zeros((n_features,))
        for _ in range(self.n_iterations):
            derivative = ((X_b.T).dot(X_b)).dot(theta)-(X_b.T).dot(y)
            theta -= self.learning_rate * derivative
        self.intercept = theta[0]
        self.coefficients = theta[1:]

    def predict(self, X):
        return X.dot(self.coefficients) + self.intercept

# Experiment 5: Study effect of different learning rates
learning_rates = [0.001, 0.01, 0.1]
rmse_scores = []
intps = []
coeffs= []

for lr in learning_rates:
    lr_gradient = LR_Gradient(learning_rate=lr)
    lr_gradient.fit(dataset_altered_features_train, dataset_altered_target_train)
    intps.append(lr_gradient.intercept)
    coeffs.append(lr_gradient.coefficients)
    dataset_altered_target_pred_gradient = lr_gradient.predict(dataset_altered_features_test)
    rmse_scores.append(rmse(dataset_altered_target_test, dataset_altered_target_pred_gradient))

# Find the optimal learning rate
optimal_lr_index = np.argmin(rmse_scores)
optimal_lr = learning_rates[optimal_lr_index]
print("Optimal Learning Rate:", optimal_lr)
print("Intercept of Optimal Learning Rate",intps[optimal_lr_index])
print("Coefficients of Optimal Learning Rate",coeffs[optimal_lr_index])

# Train with optimal learning rate
lr_gradient_optimal = LR_Gradient(learning_rate=optimal_lr)
lr_gradient_optimal.fit(dataset_altered_features_train, dataset_altered_target_train)
dataset_altered_target_pred_gradient_optimal = lr_gradient_optimal.predict(dataset_altered_features_test)

# Calculate RMSE with optimal learning rate
rmse_gradient_optimal = rmse(dataset_altered_target_test, dataset_altered_target_pred_gradient_optimal)
print("RMSE with Optimal Learning Rate:", rmse_gradient_optimal)